{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 12 - CLASSIFICATION EVALUATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perguntas a responder hoje\n",
    "\n",
    "- Como avaliar o desempenho de um modelo\n",
    "- Como obter estimativas confiáveis\n",
    "- Como comparar o desempenho relativo entre os modelos concorrentes\n",
    "\n",
    "\n",
    "# Metricas para Avaliação de Performance\n",
    "---\n",
    "\n",
    "Vamos focar-nos na capacidade de estimação de um modelo (e não tanto no seu tempo de processamento, escalabilidade, etc.)\n",
    "\n",
    "\n",
    "<img src=\"images/Log_regr.png\" style=\"width:50%\" />\n",
    "\n",
    "Vamos considerar duas Classes: **{POSITIVO, NEGATIVO}**\n",
    "> estes nomes para as classes de classificação são genericamente adoptados quando falamos de avaliação de modelos de classificação, sem perda de generalidade.\n",
    "\n",
    "O que acontece quando traçamos uma fronteira entre duas classes (Exemplo Binário)? Existem 4 possibilidades para cada exemplar classificado:\n",
    "\n",
    "- **Verdadeiros Positivos** - true positive (TP), equivalent with **hit**\n",
    "\n",
    "- **Verdadeiros Negativos** - true negative (TN), equivalent with correct rejection\n",
    "\n",
    "- **Falsos Positivos** - false positive (FP), equivalent with **false alarm**, Type I error\n",
    "\n",
    "- **Falsos Negativos** - false negative (FN), equivalent with **miss**, Type II error\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "Apesar de poder ser aplicada a modelos com qualquer número de classes, o seu funcinamento é mais claro para problemas binários:\n",
    "\n",
    "<img src=\"images/confusion_matrix.png\" style=\"width:60%\"/>\n",
    "\n",
    "Vamos imaginar duas gausseanas, uma para cada classe de classificação (Positive e Negative - que vem do campo da medicina), mediante o valor de uma feature, x. Vamos também traçar um threshold ```t```, ,abaixo do qual o nosso modelo assigna a classe Negative e acima do qual Positive, tal como mostra a figura:\n",
    "\n",
    "<img src=\"images/confusion_gaussian.png\" style=\"width:60%\"/>\n",
    "\n",
    "(ambas as gausseanas somam 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "##### Accuracy (precisão) (mais usada): \n",
    "$$\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "##### Sensitivity, recall, hit rate, or true positive rate (TPR):\n",
    "$$\\frac{TP}{TP+FN}$$\n",
    "\n",
    "##### False positive rate (FPR):\n",
    "$$\\frac{FP}{TN+FP}$$\n",
    "\n",
    "##### Specificity or true negative rate (TNR)\n",
    "$$\\frac{TN}{TN+FP}$$\n",
    "\n",
    "##### False negative rate (FNR):\n",
    "$$\\frac{FN}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "\n",
    "A curva de característica operacional do receptor (ROC) é uma abordagem gráfica para exibir o tradeoff entre o True Positive Rate (TPR) e a False Positive Rate (FPR) de um classificador. Numa curva ROC o TPR é plotado ao longo do eixo y e o FPR é mostrada no eixo x. \n",
    "\n",
    "Cada ponto ao longo da curva corresponde a um dos possiveis modelos criados pelo classificador, consoante o valor de Threshold.\n",
    "\n",
    "<img src=\"images/ROC_1.png\" style=\"width:60%\"/>\n",
    "> ROC curve plots TP (on the y-axis) against FP (on the x-axis)\n",
    "\n",
    "Vamos analisar como funciona:\n",
    "\n",
    "#### TPR (TRUE POSITIVE RATE ) = 0.5\n",
    "\n",
    "$$0.5/(0.5+0.5) = 0.5$$\n",
    "\n",
    "<img src=\"images/TPR.png\" style=\"width:20%\"/>\n",
    "\n",
    "#### FPR (FALSE POSITIVE RATE) = 0.12\n",
    "\n",
    "$$0.12/(0.12+0.88) = 0.12$$\n",
    "\n",
    "<img src=\"images/FPR.png\" style=\"width:20%\"/>\n",
    "\n",
    "Ou seja, \n",
    "\n",
    "<img src=\"images/ROC_2.png\" style=\"width:40%\"/>\n",
    "\n",
    "\n",
    "#### Posições limite na ROC Curve:\n",
    "\n",
    "- (x = 0, y = 0): declara tudo como classe negativa\n",
    "- (x = 1, y = 1): declara tudo como classe positiva\n",
    "- (x = 0, y = 1): ideal\n",
    "- (x = 1, y = 0): oposto do ideal - (tb ideal para classes binárias)\n",
    "\n",
    "\n",
    "- Um bom classificador deve ter a capacidade de ter um valor de threshold que maximiza o TPR (~1) e minimiza o FPR (~0). \n",
    "- Um mau classificador deve ter ambos os valores praticamente iguais...\n",
    "\n",
    "\n",
    "#### Comparando modelos usando ROC Curve\n",
    "\n",
    "Genericamente, o melhor modelo será aquele que se apróxima da posição (x=0,y=1). \n",
    "\n",
    "<img src=\"images/ROC_3.png\" style=\"width:40%\"/>\n",
    "\n",
    "##### E neste caso?\n",
    "\n",
    "- Nenhum modelo supera de forma consistente o outro\n",
    "    - M1 é melhor para FPR pequeno\n",
    "    - M2 é melhor para FPR grande\n",
    "\n",
    "O FPR pode ser mais ou menos relevante para um problema. Como medir a importância dos erros que nos nosso modelos geram?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos o exemplo de classificação de uma transação de um cartão de crédito ser VÁLIDA ou NÃO VÁLIDA (fraudulenta). O que é mais custoso para a empresa de transacções, que paga indeminizações quando acontece uma fraude? \n",
    "\n",
    "- Proibir uma transação que era VÁLIDA (Classificado como Negativo, apesar de ser Positivo - FN) \n",
    "- Deixar passar uma transação fraudulenta (Classificado como Positivo, apesar de ser Negativo - FP)\n",
    "\n",
    "Imaginemos que alguém na empresa consegue medir o custo relativo para a empresa de ambas as situações:\n",
    "\n",
    "e se apercebe que a primeira é 100 vezes menos grave que a segunda. \n",
    "\n",
    "#### Como podemos medir o impacto desta gravidade nos nossos modelos? \n",
    "\n",
    "#### R: Matriz de Custo, da função custo ou das métricas \"pesadas\" (e.g. Weigthed Accuracy) \n",
    "\n",
    "\n",
    "<img src=\"images/cost_matrix.png\" style=\"width:40%\"/>\n",
    "\n",
    "$C (i \\space|\\space j)$: Custo de classificação incorreta do exemplo da classe $j$ como classe $i$\n",
    "\n",
    "\n",
    "<img src=\"images/cost_application_1.png\" style=\"width:40%\"/>\n",
    "> Aplicando a função de Custo podemos ver que apesar do modelo M1 ser menos preciso (Accuracy menor) tem menos \"Custo\" \n",
    "\n",
    "\n",
    "\n",
    "Outra forma é calcularmos as métricas com pesos dados pela matriz de custos:\n",
    "\n",
    "$$Weigthed \\space Accuracy = \\frac{C(Y|Y)\\space TP + C(N|N)\\space TN}{C(Y|Y)\\space TP + C(N|Y)\\space FN + C(Y|N)\\space FP +  C(N|N)\\space TN}$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
